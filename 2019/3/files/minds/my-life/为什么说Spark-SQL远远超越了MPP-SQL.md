> [Apache Spark Future](https://0x0fff.com/apache-spark-future/) 吐槽Spark,其实我看了半天没看懂他在说啥。不过总体而言DataBricks公司目前很多的做法其实蛮合我的理念的。

## 前言

这里说的并不是性能，因为我没尝试对比过（下文会有简单的说明），而是尝试从某种更高一层次的的角度去看，为什么Spark SQL 是远远超越MPP SQL的。

Spark SQL 和  MPP SQL 其实不在一个维度上。简而言之，

*  MPP SQL 是 Spark SQL 的一个子集
*  Spark SQL 成为了一种跨越领域的交互形态

## MPP SQL 是 Spark SQL 的一个子集

MPP SQL 要解决的技术问题是海量数据的查询问题。这里根据实际场景，你还可以加上一些修饰词汇，譬如秒级，Ad-hoc 之类。

在实际业务中

1. 探索类业务，比如KPI多维分析，用户画像查询，数据科学家摸底数据等
2. 运营类业务，比如报表（现在很多BI系统基本上完全基于SQL来构建），各种运营临时统计需求
3. 分析类业务，不过这个会比较浅显。显然，真实的的分析应该主要依托一些统计类，机器学习等技术的支持
4. 运维类业务，比如实时查询查看海量的系统日志等

MPP SQL 是有一定的性能优势的，从HAWQ,Impala 等都是基于MPP架构的。然而仅限于此。这些功能Spark SQL 目前都已经涵盖了，MPP SQL能做的事情，Spark SQL都完成的很漂亮。

依托于Spark 自身的全平台性(漂亮的DataSource API以及各个厂商的努力适配),Spark SQL 基本上可以对接任意多个异构数据源进行分析和查询。大家可参考我的一个简略实现 [利用StreamingPro实现SQL-交互式查询](https://github.com/allwefantasy/streamingpro/wiki/利用StreamingPro实现SQL-交互式查询)。

关于性能可以再多说两句：

* 得益于一些具有复杂存储格式的文件的诞生，譬如CarbonData, Spark SQL 已经实现海量数据的秒级查询
* Spark 自身通过Tungsten等项目的优化(尤其是代码自动生成)，速度越来越生猛，而JVM譬如GC带来的问题则可以进一步通过off-heap的方式减少。

所以 Spark SQL 和 MPP SQL在性能上的差距也会越来越小。


# Spark SQL 成为了一种跨越领域的交互形态

Spark 通过使用DS（2.0统一了DF 和 DS，使用一套SQL引擎）极大的增强了交互语意，意味着你可以用SQL（DS）作为统一的交互语言完成流式，批处理，交互式查询，机器学习等大数据领域常见场景。这在任何一个系统都是不多见的，也可见Spark团队的抽象能力。

引言中的那篇文章其实是作者吐槽Spark 团队对Spark core（RDD）那层关注太少了，所以开始发牢骚。

现在我们再回过头来看我们常见的一些业务：

1. 实时分析类业务 
2. 探索类业务
3. 分析预测类业务
4. 运营报表类业务

首先这些业务都可以使用Spark 来实现。其次统一的交互接口都是DS(DF/SQL),并且DS/SQL 是一套极度易用并且广泛普及和接受的。

当然Spark 也不是一步就做到这点的，原来流式计算和批量计算就是两套API, DF 和 DS 也是两套API,后面经过发展，Databricks 团队也在积极思考和慢慢成长，经过先前已经有的积累，才做到现在的这一步。


> 所以本质上DS/SQL 已经成为除了RDD API 以外，另外一套通用的，统一的交互式API，涵盖了流式，批处理，交互式查询，机器学习等大数据领域。这也是我们第一次达成这样的统一，目前来看也仅在Spark平台上得以实现，它是的大数据的使用和学习门槛进一步降低，功在千秋。

## RDD VS DS/SQL

DS/SQL 是一套数据类型首先，操作种类受限的表达语言，意味着Spark 团队可以做更好的性能优化，也意味着门槛更低，在易用性和性能上都能取得良好的平衡
