> 一般而言，实现某个特定业务的数据Pipeline都会比较长，这个时候对其中某个组件进行变更就是很有压力的事情。我们如何保证数据的准确性和完整性呢？


## 引子

以我们公司的实时带宽计算为例，就是一个长长的Pipeline,中间经过的组件其实是很多的，比如解析模块，指标拼接模块，累加器模块等，这些模块根据业务需求也会经常发生变更。

因为最终数据需要每一个环节的衔接和计算都没有问题，才能得出正确的结果。然而让人遗憾的是，一个变更可能不影响最终呈现，但是其实是有问题的。那问题来了，发生变更后，如何保证数据的正确性？ 

需要做的事情其实很多的。经过实践，我们发现如下四个举措可以减少变更带来的风险。

## 变更前并行运行

通常我们有一个模块变更后，我们会在准生产环境并行运行一段时间(一般而言是一周)，对计算结果会绘制成曲线图，然后和线上的曲线进行拟合。如果完全重叠，则证明没有问题，具备上线条件。

这个可以保证数据的准确性

## 探针

探针可以检测全流程数据是否会丢失，而且能检验延时情况。 探针可以是数据源提供的，也可以是自己仿造的。

这个可以一定程度上保证数据的完整性。

##  离线数据存储

离线数据需要得到保留,可以是最原始的数据，也可以是某个中间结果的数据，还可以是某个数据的偏移量(譬如Kafka的偏移量)，这样可以保证离线数据或者上线变更导致计算异常(逻辑上的或者物理上的)能够得到补救。

## 埋点统计

当然，真正要实现全链路的质量监控，保证不发生问题或者及时发现问题，还是需要对每个环节设置各种指标，我们其实对各个环节也抽象出了很多指标，通过一个高效的计数系统来实现。这里唯一的问题是需要进行埋点。

## 总结

质量控制其实是一个比较复杂的问题，上面的做的事情通过并行运算确保最终结果无异常，离线数据存储保证数据计算结果的可恢复，探针可以检测延时或者数据的完整性，埋点可以让我们对各个组件的状态有更多的追踪。
